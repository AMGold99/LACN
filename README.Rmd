---
title: "LACN 2022 Survey"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  paged.print = FALSE,
  echo = FALSE,
  fig.path = "output/"
  )
  
  load("lacn.RData")
```

This document walks you through the structure, purpose, and output of this repository. All scripts can be found in the **code** directory. 

# File Structure

```{r file-structure}
cat('Contents of lacn directory \n')
list.files("~/piper analysis/lacn")

cat('\nFiles in code subdirectory\n')
list.files("~/piper analysis/lacn/code")

cat('\nFiles in data subdirectory\n')
list.files("~/piper analysis/lacn/data")
```


# Load Data

File: **read_data.R**

The raw survey data ("lacn_2022.csv") resides in the data subdirectory of the lacn folder. The first several lines of this script load this data and remove several redundant rows. 

Next, we specify the Gooogle Sheets spreadsheet we want to connect with (this will come in handy a bit later).

The next task is creating a reference lookup table for all the questions, their descriptions, and response descriptions. We will call this our "Response Key." First we create a somewhat messy version from the raw data (**response_key_messy**). Then we send it over to Sheets for some manual cleaning before bringing it back into R, now calling it **response_key**. This will be crucial for maintaining consistent references throughout analysis and visualization.
```{r response-key}
cat('Reference Lookup Table:\n')
head(response_key, 3)
```

Our final task in this initial section is creating a table of question types. Some LACN questions are single-response, some are multi-choice (more than one can be selected), some allow for a matrix of responses per college, some a continuous numeric input, and one a ordinal ranking. If we want to automate the cleaning and analysis of the survey questions, we need to be able to separate out the single-response questions from the matrix questions, etc. The **question_type** dataframe, built manually in Google Sheets and then imported into R.

Now we can move to analyzing each question on its own terms.

# Cleaning 

File: **clean.R**

One of the challenges with this data is how *wide* it is. The raw survey dataframe contains 257 variables. If we want to speed up our analysis, we need to break the dataset up by question. That way, when we want to analyze Q8, we can simply handle the Q8 dataset without having to sift through the entire 257-column raw dataset.

**clean.R** loops through each question and extracts its columns from the master dataset, along with the name of each respondent and their size category, following Lauren's style last year. We then deposit each of those question-specific dataframes (specified as **current_question** in the for loop) into a "list," which is an object capable of containing other objects (like dataframes) within it. Now, we have a nice portable object we can manipulation, explore, and use in later analysis. Without this list, we would have to repeat ourselves every time we wanted to extract a single question and analyze it.

Below is a representation of the structure of that list (called **question_list**). As you can see, **question_list**, represented by the top-most black rectangle, contains within it 

```{r}
lobstr::ref(question_list)
```

# Functions for Analysis

File: **lacn_functions.R**

## Motivation
To get a sense for why the following custom functions are useful, let's inspect some of the raw data.

Below are several questions from the survey. 

```{r paged.print=FALSE}
cat('Question 2\n')
head(question_list$Q2)

cat('\nQuestion 4\n')
head(question_list$Q4)

cat('\nQuestion 5\n')
head(question_list$Q5)

cat('\nQuestion 6\n')
head(question_list$Q6)

cat('\nQuestion 7\n')
head(question_list$Q7)

```
A brief inspection of these questions (and the original survey format) reveals their widely varying structure. Question 2 allows for only one response per participant, while Question 4 allows for multiple responses. Question 5 requires each respondent to rank a list of items, Question 6 provides a matrix for the respondent to fill in, and Question 7 asks for an unbounded numeric input reflecting the number of FTE professional staff.

Here, we're faced with a choice. First, we could analyze each of the 23 questions individually. While that is the most attractive option up front, pursuing that path quickly presents a problem: we will end up duplicating work when one question has the same form as an earlier one and therefore can be analyzed using essentially the same method. Questions 2 and 3, for example, are both single-response items. If we analyzed them separately, we would probably just copy and paste the code from Question 2 in order to work with Question 3. 

Our second option, then, is to build some functions that can deal with each of these question types efficiently. There are only five types: single, multi, matrix, continuous, and ranking. That is a much more manageable problem.

The challenge with this approach is building those functions. Custom functions can be a bit intimidating at first, but what they lack in simplicity they make up for in speed.

## Functions

Note: the summarising method of the functions can be adjusted. Currently they return averages when relevant, but we can change this to, for example, sum with little difficulty.

### Helper Functions
In **lacn_functions.R**, we find a handful of functions. First up are two helper functions: *selectionFunction*, which returns a vector of questions (e.g., c("Q4","Q7","Q2"...)) that belong to a certain question type, like "matrix", and *keyFunction*, which returns a reference table for response labels. Don't worry too much about these; they just end up getting wrapped into the main functions below.

### Analysis Functions

The four main types of question each get their own function (single, multi, matrix, and continuous). *Ranking* does not, as there is only one such question; building a function would be more trouble than it's worth. 
Without getting into too much detail, here's how each of them works

#### Single Function and Multi Function

Both of these merely group and aggregate the number of times each response was selected, then add a variable for the relative frequency of each response (with the denominator being the total number of respondents).

```{r single multi, paged.print=FALSE}
cat('Original data:\n')
head(question_list$Q2)
cat('\nAggregated data:\n')
head(all_list$single$Q2)
```

#### Matrix Function

The matrix function pivots then unpivots each question so that the matrix format of the original survey is recovered. It then summarises the responses in each cell.

```{r}
cat('Original data:\n')
head(question_list$Q6)

cat('\nAggregated data:\n')
head(all_list$matrix$Q6)


```


#### Continuous Function

The continuous function pivots and aggregates data by response to return some statistic on each response category.
```{r}
cat('Original data:\n')
head(question_list$Q7)

cat('\nAggregated data:\n')
head(all_list$continuous$Q7)

```
#### Ranking Analysis

The ranking question (Q5) doesn't get its own function. Here's how the analysis works (see **analysis.R**). We simply compute the desired statistic for the ranking of each "priority" (student engagment, first destination data) and then pivot the resultant dataset in anticipation of visualization.

#### Analyze Function

Finally, the analyze function allows us to do all of the above analysis for each question type in just a few lines of code (see next section).


# Analysis

File: **analysis.R**

Next, we apply the functions we built to the original data we have stored in **question_list**. The analyzeFunction that we built above allows us analyze any set of questions. That is, if we choose only the "single" questions, it will apply the singleFunction to them.

The map function (see [purrr](https://purrr.tidyverse.org/) for more) allows us to do exactly this. Let me explain the code below:
```{r}
all_questions <- unique(question_type$q_type)[c(2,3,5,6)]
cat('all_questions:\n')
all_questions
```

```r
all_list <- map(all_questions,
                ~ analyzeFunction(
                  .x
                )
)
```

The first argument in the map function is the **all_questions** vector. The second argument is the function we want to apply to each element in that vector (the '.x' is just a placeholder to represent each element in the vector). So first it will apply the singleFunction to the single questions, then the multiFunction to the multi questions, and so on, storing each question type separately in the list we're calling **all_list**. After this code, the **analysis.R** script goes on to add the ranking question into **all_list** separately, as it did not have a function.


## What did we create?
We now have a list containing the cleaned and summarised data for each type of question (single, multi, matrix, continuous, ranking). See the structure map below to get a sense of how the final data is stored. It can look a bit chaotic at first, but the basic idea is this: the master list contains different question types, which each contain the relevant questions, which each contain the actual variables and data for each summarised and aggregated response.

```{r list structure}
lobstr::ref(all_list)
```

Let's say you wanted to investigate conference attendance rates (Q9). You would note that Q9 is a multi-response question:

```{r q9 type}
question_type |> dplyr::filter(unique=="Q9")
```
Next, you would key into the master list in the following order: master list --> question type --> question. The '$' in the code below are how R digs into a deeper level of some object, like a list or a dataframe. Think of it as opening a door into an inner room of a house.

```{r list explore}
all_list$multi$Q9
```


# Visualization

File: **lacn_viz.R**

*In progress. Please check back later.*


